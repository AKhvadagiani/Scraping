{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Processing: Clean and preprocess the extracted HTML data:\n",
    "\n",
    "Remove HTML tags and scripts.\n",
    "Normalize text (lowercasing, removing punctuation).\n",
    "Tokenization and stop-word removal can be beneficial.\n",
    "\n",
    "\n",
    "Feature Extraction: Identify and extract relevant features that could help classify a domain as an eCommerce store:\n",
    "\n",
    "Keywords and phrases.\n",
    "HTML structure elements (e.g., presence of <product>, <price>, <cart> tags).\n",
    "Meta tags relevant to eCommerce.\n",
    "\n",
    "\n",
    "LLM Utilization:\n",
    "\n",
    "Use large language models (like GPT-3, BERT) to classify extracted text or assist in feature selection. Fine-tuning these models on your labeled data could yield excellent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import warnings\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import spacy\n",
    "import numpy as np\n",
    "import emoji\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1=pd.read_csv('noshop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12045, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phrases to search for\n",
    "# phrases_to_search = [\n",
    "#     \"Terms and conditions\",\n",
    "#     \"Privacy policy\",\n",
    "#     \"Return and exchange policy\",\n",
    "#     \"Place a return or exchange request\",\n",
    "#     \"Track your order\",\n",
    "#     \"Add to cart\",\n",
    "#     \"add to cart\",\n",
    "#     \"select product\",\n",
    "#     \"Online shop\",\n",
    "#     \"Shipping & Payment\",\n",
    "#     \"Exchanges & Refunds\",\n",
    "#     \"How to Shop\",\n",
    "#     \"Order Status\",\n",
    "#     \"Shipping Method\",\n",
    "#     \"Trackin order\",\n",
    "#     \"User Guide \",\n",
    "#     \"online e-commerce\",\n",
    "#     \"Quick buy\",\n",
    "#     \"Easy Return Guidance\",\n",
    "#     \"Shipping Details\",\n",
    "#     \"Online shop\",\n",
    "#     \"Delivery\",\n",
    "#     \"RETURNS AND EXCHANGE\",  \n",
    "#     \"Payment methods\",\n",
    "#     \"Returns and refunds\",\n",
    "#     \"Shipping Information & Costs\",\n",
    "#     \"Shopping basket\",\n",
    "#     \"Loyalte program\",\n",
    "#     \"Gift Cards\",\n",
    "#     \"Shipping and payment\",\n",
    "#     \"Returns / Product exchange\",\n",
    "#     \"Payment\", \n",
    "#     \"Shipping & Delivery\",\n",
    "#     \"Exchanges & Returns\",\n",
    "#     \"Shipping and Exchange Policy\",\n",
    "#     \"Shopping basket\",\n",
    "#     \"Refund policy\",\n",
    "#     \"All about shopping\",\n",
    "#     \"Basket\",\n",
    "#     \"Shopping cart\",\n",
    "#     \"Return procedure\",\n",
    "#     \"Payment methods\",\n",
    "#     \"Guarantees and returns\",\n",
    "#     \"Return/Complaint Instructions\",\n",
    "#     \"About Click & Collect\", # \"https://www.bike-online.jp/hpgen/HPB/entries/43.html\"\n",
    "#     \"E-shop\",\n",
    "#     \"order status \"\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Suppress SSL warnings\n",
    "# # warnings.filterwarnings(\"ignore\", category=requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "# warnings.simplefilter(action='ignore')\n",
    "# # Function to fetch HTML content from the domain\n",
    "# def fetch_html(domain):\n",
    "#     headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.get(f'https://{domain}', headers=headers, timeout=10, verify=False)\n",
    "#         if response.status_code == 200:\n",
    "#             return response.text\n",
    "#         else:\n",
    "#             return \"\"\n",
    "#     except requests.RequestException:\n",
    "#         return \"\"\n",
    "\n",
    "# # Function to extract and clean text from the HTML\n",
    "# def extract_text_from_domain(domain):\n",
    "#     # Fetch HTML content using fetch_html\n",
    "#     html = fetch_html(domain)\n",
    "#     if not html:\n",
    "#         return \"Error fetching the webpage.\"\n",
    "\n",
    "#     try:\n",
    "#         soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#         # Extract text from all elements and clean it\n",
    "#         text = soup.get_text(separator=\" \")\n",
    "#         cleaned_text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "#         return cleaned_text\n",
    "#     except Exception as e:\n",
    "#         return f\"Error extracting text: {e}\"\n",
    "\n",
    "# # Function to search for specific phrases\n",
    "# def search_phrases(html_content, phrases):\n",
    "#     if not isinstance(html_content, str):\n",
    "#         return ''\n",
    "#     found_phrases = []\n",
    "#     for phrase in phrases:\n",
    "#         if phrase.lower() in html_content.lower():\n",
    "#             found_phrases.append(phrase)\n",
    "#     return ', '.join(found_phrases)\n",
    "\n",
    "# # Function to translate text\n",
    "# def translate_text(text, src_language):\n",
    "#     translator = Translator()\n",
    "#     translation = translator.translate(text, src=src_language, dest=\"en\")\n",
    "\n",
    "# # Function to detect the HTML language\n",
    "# def detect_language(html_content):\n",
    "#     if not html_content:\n",
    "#         return None\n",
    "    \n",
    "#     # Use regex to find the lang attribute directly\n",
    "#     lang_match = re.search(r'<html[^>]*\\blang=[\"\\']?([a-zA-Z-]+)', html_content, re.IGNORECASE)\n",
    "#     if lang_match:\n",
    "#         detected_lang = lang_match.group(1).split('-')[0]  # Extract primary language\n",
    "#         return detected_lang\n",
    "\n",
    "#     # Fallback to BeautifulSoup parsing\n",
    "#     soup = BeautifulSoup(html_content, 'lxml')\n",
    "#     html_tag = soup.html\n",
    "#     if html_tag and html_tag.get('lang'):\n",
    "#         detected_lang = html_tag.get('lang').split('-')[0]\n",
    "#         return detected_lang\n",
    "#     return \"\"\n",
    "\n",
    "# # Apply functions to DataFrame\n",
    "# data_1['HTML'] = data_1['domain'].apply(fetch_html)\n",
    "# data_1['Text'] = data_1['domain'].apply(extract_text_from_domain)\n",
    "# data_1['found_phrases'] = data_1['HTML'].apply(lambda html: search_phrases(html, phrases_to_search))\n",
    "# data_1['language'] = data_1['HTML'].apply(detect_language)\n",
    "# data_1.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_1[data_1['HTML'].apply(lambda x: pd.notna(x) and x not in [[], \"\"])]\n",
    "data_1 = data_1[data_1[\"Text\"].apply(lambda x: not isinstance(x, float))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9744, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_symbols_to_change = {\n",
    "    \"\\u2714\": ' ',  # ✔\n",
    "    \"\\u2605\": ' ',  # ★\n",
    "    \"\\u00A9\": ' ',  # ©\n",
    "    \"\\u00AE\": ' ',  # ®\n",
    "    \"\\u2022\": ' ',  # •\n",
    "    \"\\u2798\": ', ',  # ➨\n",
    "    \"\\u27BD\": ', ',  # ➽\n",
    "    \"\\u2661\": ', ',  # ♡\n",
    "    \"\\u266A\": ', ',  # ♪\n",
    "    \"\\u2026\": ', ',  # …\n",
    "    \"\\u25CF\": ', ',  # ●\n",
    "    \"\\u2122\": ' ',  # ™\n",
    "    \"\\u2713\": ' ',  # ✓\n",
    "    \"\\u2600\": ' ',  # ☀ (Stars and Sun)\n",
    "    \"\\u2665\": ' ',  # ♥ \n",
    "    \"\\U000025BA\": ' ', # ►\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_symbols(text):\n",
    "    \"\"\"\n",
    "    Replace some symbols in text as defined in lookup.dict_symbols_to_change.\n",
    "    \"\"\"\n",
    "    for key, value in dict_symbols_to_change.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')  # Replace emojis with empty string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1[\"Text\"]=data_1[\"Text\"].apply(replace_symbols)\n",
    "data_1[\"Text\"]=data_1[\"Text\"].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Text</th>\n",
       "      <th>found_phrases</th>\n",
       "      <th>language</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>arena.pl</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html lang=\"pl\"&gt;&lt;head&gt;&lt;link rel...</td>\n",
       "      <td>Arena.pl   Platforma zakupowa   Bezpieczne zak...</td>\n",
       "      <td>Delivery, Payment, Basket, E-shop</td>\n",
       "      <td>pl</td>\n",
       "      <td>1079239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>fomosa.co.za</td>\n",
       "      <td>&lt;!DOCTYPE html&gt; &lt;html lang=\"en-US\"&gt; &lt;head&gt;&lt;scr...</td>\n",
       "      <td>FOMO | Best Deals on Activities &amp; Experiences ...</td>\n",
       "      <td>Terms and conditions, Privacy policy, Delivery...</td>\n",
       "      <td>en</td>\n",
       "      <td>293642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>blumenbilder.org</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if IE 6]&gt;\\n&lt;html id=\"ie6...</td>\n",
       "      <td>Leben mit Blumen | Blumenbilder.org IM TREND: ...</td>\n",
       "      <td>Payment</td>\n",
       "      <td>de</td>\n",
       "      <td>256146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>anzlitlovers.com</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...</td>\n",
       "      <td>ANZ LitLovers LitBlog | For lovers of Australi...</td>\n",
       "      <td>Delivery, Payment</td>\n",
       "      <td>en</td>\n",
       "      <td>241540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>fogyas.info</td>\n",
       "      <td>\\r\\n&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4....</td>\n",
       "      <td>Fogyás   A sikeres fogyás titka   Érezd jól ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hu</td>\n",
       "      <td>218860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                domain                                               HTML  \\\n",
       "695           arena.pl  <!DOCTYPE html><html lang=\"pl\"><head><link rel...   \n",
       "3860      fomosa.co.za  <!DOCTYPE html> <html lang=\"en-US\"> <head><scr...   \n",
       "1402  blumenbilder.org  <!DOCTYPE html>\\n<!--[if IE 6]>\\n<html id=\"ie6...   \n",
       "614   anzlitlovers.com  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...   \n",
       "3854       fogyas.info  \\r\\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4....   \n",
       "\n",
       "                                                   Text  \\\n",
       "695   Arena.pl   Platforma zakupowa   Bezpieczne zak...   \n",
       "3860  FOMO | Best Deals on Activities & Experiences ...   \n",
       "1402  Leben mit Blumen | Blumenbilder.org IM TREND: ...   \n",
       "614   ANZ LitLovers LitBlog | For lovers of Australi...   \n",
       "3854  Fogyás   A sikeres fogyás titka   Érezd jól ma...   \n",
       "\n",
       "                                          found_phrases language      len  \n",
       "695                   Delivery, Payment, Basket, E-shop       pl  1079239  \n",
       "3860  Terms and conditions, Privacy policy, Delivery...       en   293642  \n",
       "1402                                            Payment       de   256146  \n",
       "614                                   Delivery, Payment       en   241540  \n",
       "3854                                                NaN       hu   218860  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[\"len\"]=data_1[\"Text\"].apply(len)\n",
    "data_1.sort_values(\"len\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_1[(data_1[\"len\"] >= 1000) & (data_1[\"len\"] <= 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_1=data_1.drop(columns=[\"HTML\",\"len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Text</th>\n",
       "      <th>found_phrases</th>\n",
       "      <th>language</th>\n",
       "      <th>len</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101shop.com</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html&gt;\\r\\n&lt;head&gt;\\r\\n    &lt;me...</td>\n",
       "      <td>å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12913</td>\n",
       "      <td>å åç è§£æ æ-2020å åç è§£æ æä è1⁄21⁄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001cartes.com</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n&lt;html lang=\"fr\"&gt;\\n\\t&lt;head&gt;\\n\\...</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "      <td>Add to cart, add to cart, Shipping Method, Pay...</td>\n",
       "      <td>fr</td>\n",
       "      <td>7773</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001cuponesdedescuento.cl</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"es\"&gt;\\n&lt;head&gt;\\n&lt;me...</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "      <td>Delivery, E-shop</td>\n",
       "      <td>es</td>\n",
       "      <td>13628</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain  \\\n",
       "0               0101shop.com   \n",
       "6             1001cartes.com   \n",
       "7  1001cuponesdedescuento.cl   \n",
       "\n",
       "                                                HTML  \\\n",
       "0  <!DOCTYPE html>\\r\\n<html>\\r\\n<head>\\r\\n    <me...   \n",
       "6  <!DOCTYPE HTML>\\n<html lang=\"fr\">\\n\\t<head>\\n\\...   \n",
       "7  <!DOCTYPE html>\\n<html lang=\"es\">\\n<head>\\n<me...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...   \n",
       "6  Faire-part de naissance, mariage, baptême - vo...   \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...   \n",
       "\n",
       "                                       found_phrases language    len  \\\n",
       "0                                                NaN      NaN  12913   \n",
       "6  Add to cart, add to cart, Shipping Method, Pay...       fr   7773   \n",
       "7                                   Delivery, E-shop       es  13628   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  å åç è§£æ æ-2020å åç è§£æ æä è1⁄21⁄...  \n",
       "6  Faire-part de naissance, mariage, baptême - vo...  \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(text):\n",
    "    if not isinstance(text, str):  # Ensure input is a string\n",
    "        return text\n",
    "    \n",
    "    # Decode HTML entities\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Normalize Unicode (preserve foreign letters, remove accents)\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFKC', text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    # Remove control characters (except line breaks)\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', text)  \n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Apply normalization function\n",
    "data_1['normalized_text'] = data_1['Text'].astype(str).apply(normalize_text)\n",
    "\n",
    "# Display the result\n",
    "data_1.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8641, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_consecutive_duplicates(text):\n",
    "    return re.sub(r'\\b(\\w+)(\\s+\\1)+\\b', r'\\1', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>HTML</th>\n",
       "      <th>Text</th>\n",
       "      <th>found_phrases</th>\n",
       "      <th>language</th>\n",
       "      <th>len</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101shop.com</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html&gt;\\r\\n&lt;head&gt;\\r\\n    &lt;me...</td>\n",
       "      <td>å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12913</td>\n",
       "      <td>å åç è§£æ-2020å åç è§£æä è1⁄21⁄2-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001cartes.com</td>\n",
       "      <td>&lt;!DOCTYPE HTML&gt;\\n&lt;html lang=\"fr\"&gt;\\n\\t&lt;head&gt;\\n\\...</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "      <td>Add to cart, add to cart, Shipping Method, Pay...</td>\n",
       "      <td>fr</td>\n",
       "      <td>7773</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001cuponesdedescuento.cl</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"es\"&gt;\\n&lt;head&gt;\\n&lt;me...</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "      <td>Delivery, E-shop</td>\n",
       "      <td>es</td>\n",
       "      <td>13628</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100comments.com</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;html lang=\"en-US\"&gt;\\n&lt;head&gt;\\n...</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "      <td>Privacy policy</td>\n",
       "      <td>en</td>\n",
       "      <td>7670</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100sp.ru</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"ru\"&gt;\\n&lt;head&gt;\\n   ...</td>\n",
       "      <td>100sp — интернет-магазин. Товары по выгодным ц...</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>ru</td>\n",
       "      <td>28787</td>\n",
       "      <td>100sp — интернет-магазин. Товары по выгодным ц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12034</th>\n",
       "      <td>zuzu.deals</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html dir=\"rtl\" lang=\"h...</td>\n",
       "      <td>ZUZU DEALS - הקופונים והמבצעים הטובים ברשת! | ...</td>\n",
       "      <td>Payment</td>\n",
       "      <td>he</td>\n",
       "      <td>11552</td>\n",
       "      <td>ZUZU DEALS - הקופונים והמבצעים הטובים ברשת! | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12036</th>\n",
       "      <td>zwift.com</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html lang=\"de\" data-locale=\"de...</td>\n",
       "      <td>Zwift | Die Indoor-Radfahrapp für Smart Traine...</td>\n",
       "      <td>Payment</td>\n",
       "      <td>de</td>\n",
       "      <td>3880</td>\n",
       "      <td>Zwift | Die Indoor-Radfahrapp für Smart Traine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12037</th>\n",
       "      <td>zwiftinsider.com</td>\n",
       "      <td>&lt;!doctype html &gt;\\r\\n&lt;html lang=\"en-US\"&gt;\\r\\n&lt;he...</td>\n",
       "      <td>Zwift Insider | News, tips, and reviews for Zw...</td>\n",
       "      <td>Privacy policy</td>\n",
       "      <td>en</td>\n",
       "      <td>6695</td>\n",
       "      <td>Zwift Insider | News, tips, and reviews for Zw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12039</th>\n",
       "      <td>zwrotnikraka.pl</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;!--[if IE 6]&gt;\\n&lt;html id=\"ie6...</td>\n",
       "      <td>Zwrotnikraka.pl - portal onkologiczny dla Pacj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pl</td>\n",
       "      <td>13295</td>\n",
       "      <td>Zwrotnikraka.pl - portal onkologiczny dla Pacj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12040</th>\n",
       "      <td>zx123.cn</td>\n",
       "      <td>&lt;!doctype html&gt;\\n&lt;!--[if IE 6]&gt;&lt;html lang=\"en\"...</td>\n",
       "      <td>ä¸ä¸è£ ä¿ ç½_è£ ä¿ ä¸ç«å¼æå¡å¹³å°_è£...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>9962</td>\n",
       "      <td>ä ä è£ ä¿ ç1⁄2_è£ ä¿ ä ç«å1⁄4æå¡å13å...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8641 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          domain  \\\n",
       "0                   0101shop.com   \n",
       "6                 1001cartes.com   \n",
       "7      1001cuponesdedescuento.cl   \n",
       "8                100comments.com   \n",
       "9                       100sp.ru   \n",
       "...                          ...   \n",
       "12034                 zuzu.deals   \n",
       "12036                  zwift.com   \n",
       "12037           zwiftinsider.com   \n",
       "12039            zwrotnikraka.pl   \n",
       "12040                   zx123.cn   \n",
       "\n",
       "                                                    HTML  \\\n",
       "0      <!DOCTYPE html>\\r\\n<html>\\r\\n<head>\\r\\n    <me...   \n",
       "6      <!DOCTYPE HTML>\\n<html lang=\"fr\">\\n\\t<head>\\n\\...   \n",
       "7      <!DOCTYPE html>\\n<html lang=\"es\">\\n<head>\\n<me...   \n",
       "8      <!doctype html>\\n<html lang=\"en-US\">\\n<head>\\n...   \n",
       "9      <!DOCTYPE html>\\n<html lang=\"ru\">\\n<head>\\n   ...   \n",
       "...                                                  ...   \n",
       "12034      <!DOCTYPE html>\\r\\n<html dir=\"rtl\" lang=\"h...   \n",
       "12036  <!DOCTYPE html><html lang=\"de\" data-locale=\"de...   \n",
       "12037  <!doctype html >\\r\\n<html lang=\"en-US\">\\r\\n<he...   \n",
       "12039  <!DOCTYPE html>\\n<!--[if IE 6]>\\n<html id=\"ie6...   \n",
       "12040  <!doctype html>\\n<!--[if IE 6]><html lang=\"en\"...   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...   \n",
       "6      Faire-part de naissance, mariage, baptême - vo...   \n",
       "7      Cupones de descuento en Chile hasta 80% OFF en...   \n",
       "8      Product Reviews, Free Samples, New Products @ ...   \n",
       "9      100sp — интернет-магазин. Товары по выгодным ц...   \n",
       "...                                                  ...   \n",
       "12034  ZUZU DEALS - הקופונים והמבצעים הטובים ברשת! | ...   \n",
       "12036  Zwift | Die Indoor-Radfahrapp für Smart Traine...   \n",
       "12037  Zwift Insider | News, tips, and reviews for Zw...   \n",
       "12039  Zwrotnikraka.pl - portal onkologiczny dla Pacj...   \n",
       "12040  ä¸ä¸è£ ä¿ ç½_è£ ä¿ ä¸ç«å¼æå¡å¹³å°_è£...   \n",
       "\n",
       "                                           found_phrases language    len  \\\n",
       "0                                                    NaN      NaN  12913   \n",
       "6      Add to cart, add to cart, Shipping Method, Pay...       fr   7773   \n",
       "7                                       Delivery, E-shop       es  13628   \n",
       "8                                         Privacy policy       en   7670   \n",
       "9                                               Delivery       ru  28787   \n",
       "...                                                  ...      ...    ...   \n",
       "12034                                            Payment       he  11552   \n",
       "12036                                            Payment       de   3880   \n",
       "12037                                     Privacy policy       en   6695   \n",
       "12039                                                NaN       pl  13295   \n",
       "12040                                                NaN       en   9962   \n",
       "\n",
       "                                         normalized_text  \n",
       "0      å åç è§£æ-2020å åç è§£æä è1⁄21⁄2-01...  \n",
       "6      Faire-part de naissance, mariage, baptême - vo...  \n",
       "7      Cupones de descuento en Chile hasta 80% OFF en...  \n",
       "8      Product Reviews, Free Samples, New Products @ ...  \n",
       "9      100sp — интернет-магазин. Товары по выгодным ц...  \n",
       "...                                                  ...  \n",
       "12034  ZUZU DEALS - הקופונים והמבצעים הטובים ברשת! | ...  \n",
       "12036  Zwift | Die Indoor-Radfahrapp für Smart Traine...  \n",
       "12037  Zwift Insider | News, tips, and reviews for Zw...  \n",
       "12039  Zwrotnikraka.pl - portal onkologiczny dla Pacj...  \n",
       "12040  ä ä è£ ä¿ ç1⁄2_è£ ä¿ ä ç«å1⁄4æå¡å13å...  \n",
       "\n",
       "[8641 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['normalized_text']=data_1['normalized_text'].apply(remove_consecutive_duplicates)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_1[\"lang_len\"]=data_1[\"language\"].astype(str).apply(len)\n",
    "# data_1 = data_1[data_1[\"lang_len\"] == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>Text</th>\n",
       "      <th>found_phrases</th>\n",
       "      <th>language</th>\n",
       "      <th>normalized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101shop.com</td>\n",
       "      <td>å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>å åç è§£æ-2020å åç è§£æä è1⁄21⁄2-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001cartes.com</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "      <td>Add to cart, add to cart, Shipping Method, Pay...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001cuponesdedescuento.cl</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "      <td>Delivery, E-shop</td>\n",
       "      <td>es</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100comments.com</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "      <td>Privacy policy</td>\n",
       "      <td>en</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100sp.ru</td>\n",
       "      <td>100sp — интернет-магазин. Товары по выгодным ц...</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>ru</td>\n",
       "      <td>100sp — интернет-магазин. Товары по выгодным ц...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain  \\\n",
       "0               0101shop.com   \n",
       "6             1001cartes.com   \n",
       "7  1001cuponesdedescuento.cl   \n",
       "8            100comments.com   \n",
       "9                   100sp.ru   \n",
       "\n",
       "                                                Text  \\\n",
       "0  å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...   \n",
       "6  Faire-part de naissance, mariage, baptême - vo...   \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...   \n",
       "8  Product Reviews, Free Samples, New Products @ ...   \n",
       "9  100sp — интернет-магазин. Товары по выгодным ц...   \n",
       "\n",
       "                                       found_phrases language  \\\n",
       "0                                                NaN      NaN   \n",
       "6  Add to cart, add to cart, Shipping Method, Pay...       fr   \n",
       "7                                   Delivery, E-shop       es   \n",
       "8                                     Privacy policy       en   \n",
       "9                                           Delivery       ru   \n",
       "\n",
       "                                     normalized_text  \n",
       "0  å åç è§£æ-2020å åç è§£æä è1⁄21⁄2-01...  \n",
       "6  Faire-part de naissance, mariage, baptême - vo...  \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...  \n",
       "8  Product Reviews, Free Samples, New Products @ ...  \n",
       "9  100sp — интернет-магазин. Товары по выгодным ц...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_last(text):\n",
    "    encoded_text = text\n",
    "\n",
    "    # Using UTF-8 encoding and ignoring errors\n",
    "    decoded_text = encoded_text.encode('latin1', errors='ignore').decode('utf-8', errors='ignore')\n",
    "    return decoded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>Text</th>\n",
       "      <th>found_phrases</th>\n",
       "      <th>language</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>Decode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101shop.com</td>\n",
       "      <td>å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>å åç è§£æ-2020å åç è§£æä è1⁄21⁄2-01...</td>\n",
       "      <td>卓 解戏-2020 卓 解戏 1212-0101手 12 0101手 1214 新的手o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001cartes.com</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "      <td>Add to cart, add to cart, Shipping Method, Pay...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Faire-part de naissance, mariage, baptême - vo...</td>\n",
       "      <td>Faire-part de naissance, mariage, baptme - vos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001cuponesdedescuento.cl</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "      <td>Delivery, E-shop</td>\n",
       "      <td>es</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "      <td>Cupones de descuento en Chile hasta 80% OFF en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100comments.com</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "      <td>Privacy policy</td>\n",
       "      <td>en</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "      <td>Product Reviews, Free Samples, New Products @ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain  \\\n",
       "0               0101shop.com   \n",
       "6             1001cartes.com   \n",
       "7  1001cuponesdedescuento.cl   \n",
       "8            100comments.com   \n",
       "\n",
       "                                                Text  \\\n",
       "0  å åç ´è§£æ¸¸æ-2020å åç ´è§£æ¸¸æä¸è½...   \n",
       "6  Faire-part de naissance, mariage, baptême - vo...   \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...   \n",
       "8  Product Reviews, Free Samples, New Products @ ...   \n",
       "\n",
       "                                       found_phrases language  \\\n",
       "0                                                NaN      NaN   \n",
       "6  Add to cart, add to cart, Shipping Method, Pay...       fr   \n",
       "7                                   Delivery, E-shop       es   \n",
       "8                                     Privacy policy       en   \n",
       "\n",
       "                                     normalized_text  \\\n",
       "0  å åç è§£æ-2020å åç è§£æä è1⁄21⁄2-01...   \n",
       "6  Faire-part de naissance, mariage, baptême - vo...   \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...   \n",
       "8  Product Reviews, Free Samples, New Products @ ...   \n",
       "\n",
       "                                              Decode  \n",
       "0   卓 解戏-2020 卓 解戏 1212-0101手 12 0101手 1214 新的手o ...  \n",
       "6  Faire-part de naissance, mariage, baptme - vos...  \n",
       "7  Cupones de descuento en Chile hasta 80% OFF en...  \n",
       "8  Product Reviews, Free Samples, New Products @ ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[\"Decode\"]=data_1[\"normalized_text\"].apply(decode_last)\n",
    "\n",
    "data_1.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Translation pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the model once globally\n",
    "# nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "# nlp.add_pipe('sentencizer')\n",
    "\n",
    "# def Tokenizer(text):\n",
    "#     \"\"\"Tokenize a text into sentences using spaCy.\"\"\"\n",
    "#     if pd.isna(text) or not isinstance(text, str):  # Handle NaN or non-string values\n",
    "#         return []\n",
    "    \n",
    "#     doc = nlp(text)\n",
    "#     return [sent.text.strip() for sent in doc.sents]  # Return a list of sentences\n",
    "\n",
    "# # Apply the function to the 'text' column\n",
    "# data_1['tokenized_sentences'] = data_1['normalized_text'].apply(Tokenizer)\n",
    "\n",
    "# data_1.head(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    return detect(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1[\"detected_language\"]=data_1[\"normalized_text\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.to_csv(\"cleaned_nonshop.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464\n"
     ]
    }
   ],
   "source": [
    "sum_mismatches = 0\n",
    "for i in range(len(data_1)):  \n",
    "    if data_1.iloc[i][\"language\"] != data_1.iloc[i][\"detected_language\"]:  \n",
    "        sum_mismatches += 1 \n",
    "print(sum_mismatches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed translation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_map = {\n",
    "    \"af\": \"afr_Latn\",\n",
    "    \"ak\": \"aka_Latn\",\n",
    "    \"am\": \"amh_Ethi\",\n",
    "    \"ar\": \"arb_Arab\",\n",
    "    \"as\": \"asm_Beng\",\n",
    "    \"ay\": \"ayr_Latn\",\n",
    "    \"az\": \"azj_Latn\",\n",
    "    \"bm\": \"bam_Latn\",\n",
    "    \"be\": \"bel_Cyrl\",\n",
    "    \"bn\": \"ben_Beng\",\n",
    "    \"bho\": \"bho_Deva\",\n",
    "    \"bs\": \"bos_Latn\",\n",
    "    \"bg\": \"bul_Cyrl\",\n",
    "    \"ca\": \"cat_Latn\",\n",
    "    \"ceb\": \"ceb_Latn\",\n",
    "    \"cs\": \"ces_Latn\",\n",
    "    \"ckb\": \"ckb_Arab\",\n",
    "    \"tt\": \"crh_Latn\",\n",
    "    \"cy\": \"cym_Latn\",\n",
    "    \"da\": \"dan_Latn\",\n",
    "    \"de\": \"deu_Latn\",\n",
    "    \"el\": \"ell_Grek\",\n",
    "    \"en\": \"eng_Latn\",\n",
    "    \"eo\": \"epo_Latn\",\n",
    "    \"et\": \"est_Latn\",\n",
    "    \"eu\": \"eus_Latn\",\n",
    "    \"ee\": \"ewe_Latn\",\n",
    "    \"fa\": \"pes_Arab\",\n",
    "    \"fi\": \"fin_Latn\",\n",
    "    \"fr\": \"fra_Latn\",\n",
    "    \"gd\": \"gla_Latn\",\n",
    "    \"ga\": \"gle_Latn\",\n",
    "    \"gl\": \"glg_Latn\",\n",
    "    \"gn\": \"grn_Latn\",\n",
    "    \"gu\": \"guj_Gujr\",\n",
    "    \"ht\": \"hat_Latn\",\n",
    "    \"ha\": \"hau_Latn\",\n",
    "    \"he\": \"heb_Hebr\",\n",
    "    \"hi\": \"hin_Deva\",\n",
    "    \"hr\": \"hrv_Latn\",\n",
    "    \"hu\": \"hun_Latn\",\n",
    "    \"hy\": \"hye_Armn\",\n",
    "    \"nl\": \"nld_Latn\",\n",
    "    \"ig\": \"ibo_Latn\",\n",
    "    \"ilo\": \"ilo_Latn\",\n",
    "    \"id\": \"ind_Latn\",\n",
    "    \"is\": \"isl_Latn\",\n",
    "    \"it\": \"ita_Latn\",\n",
    "    \"jv\": \"jav_Latn\",\n",
    "    \"ja\": \"jpn_Jpan\",\n",
    "    \"kn\": \"kan_Knda\",\n",
    "    \"ka\": \"kat_Geor\",\n",
    "    \"kk\": \"kaz_Cyrl\",\n",
    "    \"km\": \"khm_Khmr\",\n",
    "    \"rw\": \"kin_Latn\",\n",
    "    \"ko\": \"kor_Hang\",\n",
    "    \"ku\": \"kmr_Latn\",\n",
    "    \"lo\": \"lao_Laoo\",\n",
    "    \"lv\": \"lvs_Latn\",\n",
    "    \"ln\": \"lin_Latn\",\n",
    "    \"lt\": \"lit_Latn\",\n",
    "    \"lb\": \"ltz_Latn\",\n",
    "    \"lg\": \"lug_Latn\",\n",
    "    \"lus\": \"lus_Latn\",\n",
    "    \"mai\": \"mai_Deva\",\n",
    "    \"ml\": \"mal_Mlym\",\n",
    "    \"mr\": \"mar_Deva\",\n",
    "    \"mk\": \"mkd_Cyrl\",\n",
    "    \"mg\": \"plt_Latn\",\n",
    "    \"mt\": \"mlt_Latn\",\n",
    "    \"mni-Mtei\": \"mni_Beng\",\n",
    "    \"mni\": \"mni_Beng\",\n",
    "    \"mn\": \"khk_Cyrl\",\n",
    "    \"mi\": \"mri_Latn\",\n",
    "    \"ms\": \"zsm_Latn\",\n",
    "    \"my\": \"mya_Mymr\",\n",
    "    \"no\": \"nno_Latn\",\n",
    "    \"ne\": \"npi_Deva\",\n",
    "    \"ny\": \"nya_Latn\",\n",
    "    \"om\": \"gaz_Latn\",\n",
    "    \"or\": \"ory_Orya\",\n",
    "    \"pl\": \"pol_Latn\",\n",
    "    \"pt\": \"por_Latn\",\n",
    "    \"ps\": \"pbt_Arab\",\n",
    "    \"qu\": \"quy_Latn\",\n",
    "    \"ro\": \"ron_Latn\",\n",
    "    \"ru\": \"rus_Cyrl\",\n",
    "    \"sa\": \"san_Deva\",\n",
    "    \"si\": \"sin_Sinh\",\n",
    "    \"sk\": \"slk_Latn\",\n",
    "    \"sl\": \"slv_Latn\",\n",
    "    \"sm\": \"smo_Latn\",\n",
    "    \"sn\": \"sna_Latn\",\n",
    "    \"sd\": \"snd_Arab\",\n",
    "    \"so\": \"som_Latn\",\n",
    "    \"es\": \"spa_Latn\",\n",
    "    \"sq\": \"als_Latn\",\n",
    "    \"sr\": \"srp_Cyrl\",\n",
    "    \"su\": \"sun_Latn\",\n",
    "    \"sv\": \"swe_Latn\",\n",
    "    \"sw\": \"swh_Latn\",\n",
    "    \"ta\": \"tam_Taml\",\n",
    "    \"te\": \"tel_Telu\",\n",
    "    \"tg\": \"tgk_Cyrl\",\n",
    "    \"tl\": \"tgl_Latn\",\n",
    "    \"th\": \"tha_Thai\",\n",
    "    \"ti\": \"tir_Ethi\",\n",
    "    \"ts\": \"tso_Latn\",\n",
    "    \"tk\": \"tuk_Latn\",\n",
    "    \"tr\": \"tur_Latn\",\n",
    "    \"ug\": \"uig_Arab\",\n",
    "    \"uk\": \"ukr_Cyrl\",\n",
    "    \"ur\": \"urd_Arab\",\n",
    "    \"uz\": \"uzn_Latn\",\n",
    "    \"vi\": \"vie_Latn\",\n",
    "    \"xh\": \"xho_Latn\",\n",
    "    \"yi\": \"ydd_Hebr\",\n",
    "    \"yo\": \"yor_Latn\",\n",
    "    \"zh-CN\": \"zho_Hans\",\n",
    "    \"zh\": \"zho_Hans\",\n",
    "    \"zh-TW\": \"zho_Hant\",\n",
    "    \"zu\": \"zul_Latn\",\n",
    "    \"pa\": \"pan_Guru\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "# import re\n",
    "\n",
    "# # Load NLLB model and tokenizer\n",
    "# model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# def chunk_text(text, chunk_size=1000):\n",
    "#     \"\"\"Splits text into chunks of specified size, preserving sentences where possible.\"\"\"\n",
    "#     sentences = re.split(r'(?<=[.!?]) +', text)  # Split while keeping punctuation-based structure\n",
    "#     chunks = []\n",
    "#     current_chunk = []\n",
    "#     current_length = 0\n",
    "    \n",
    "#     for sentence in sentences:\n",
    "#         if current_length + len(sentence) + 1 > chunk_size:\n",
    "#             chunks.append(\" \".join(current_chunk))\n",
    "#             current_chunk = []\n",
    "#             current_length = 0\n",
    "#         current_chunk.append(sentence)\n",
    "#         current_length += len(sentence) + 1\n",
    "    \n",
    "#     if current_chunk:\n",
    "#         chunks.append(\" \".join(current_chunk))\n",
    "    \n",
    "#     return chunks\n",
    "\n",
    "# def translate_chunks(text, src_lang, batch_size=4):\n",
    "#     \"\"\"Translates text efficiently by processing in batches, preserving non-text elements.\"\"\"\n",
    "#     if not text.strip():\n",
    "#         return \"[Empty content]\"\n",
    "    \n",
    "#     if src_lang == \"en\":\n",
    "#         return text  # Skip translation if language is English\n",
    "    \n",
    "#     src_lang_nllb = lang_map.get(src_lang, None)\n",
    "#     if not src_lang_nllb:\n",
    "#         return \"[Unsupported language]\"\n",
    "    \n",
    "#     chunks = chunk_text(text)\n",
    "#     translated_chunks = []\n",
    "    \n",
    "#     for i in range(0, len(chunks), batch_size):\n",
    "#         batch = chunks[i:i+batch_size]\n",
    "#         inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#         translated_tokens = model.generate(\n",
    "#             **inputs,\n",
    "#             max_length=500,  # Increased limit for longer outputs\n",
    "#             num_beams=2,  # More beams for better quality\n",
    "#             forced_bos_token_id=tokenizer.convert_tokens_to_ids([\"eng_Latn\"])[0]\n",
    "#         )\n",
    "#         translations = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n",
    "#         translated_chunks.extend(translations)\n",
    "    \n",
    "#     return \" \".join(translated_chunks)\n",
    "\n",
    "# # Apply translation with batch processing, skipping English rows\n",
    "# data_1[\"translated_text\"] = data_1.apply(\n",
    "#     lambda row: row[\"normalized_text\"] if row[\"language\"] == \"en\" else translate_chunks(row[\"normalized_text\"], row[\"language\"]), axis=1\n",
    "# )\n",
    "\n",
    "# # Display final DataFrame\n",
    "# data_1.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful transaltion model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version I\n",
    "\n",
    "# from deep_translator import GoogleTranslator\n",
    "# import pandas as pd\n",
    "# import ast  # To safely convert string representation of lists\n",
    "\n",
    "# # Function to split long texts into chunks\n",
    "# def chunk_text(text, chunk_size=2000):\n",
    "#     return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# # Function to translate tokenized sentences\n",
    "# def translate_sentences(tokenized_list, src_lang=\"auto\", target_lang=\"en\"):\n",
    "#     if isinstance(tokenized_list, list):\n",
    "#         text = \" \".join(tokenized_list)  # Convert list to string\n",
    "#     else:\n",
    "#         text = str(tokenized_list)  # Ensure it's a string\n",
    "    \n",
    "#     # Split text into smaller chunks\n",
    "#     chunks = chunk_text(text)\n",
    "    \n",
    "#     # Translate each chunk separately\n",
    "#     translated_chunks = [\n",
    "#         GoogleTranslator(source=src_lang, target=target_lang).translate(chunk) for chunk in chunks\n",
    "#     ]\n",
    "    \n",
    "#     return \" \".join(translated_chunks)\n",
    "\n",
    "# # Apply translation conditionally\n",
    "# def apply_translation(row):\n",
    "#     if row[\"language\"] == \"en\":\n",
    "#         return row[\"tokenized_sentences\"]\n",
    "#     else:\n",
    "#         return translate_sentences(row[\"tokenized_sentences\"])\n",
    "\n",
    "# # Assuming data_1 is a Pandas DataFrame\n",
    "# data_1[\"translated_text_2\"] = data_1.apply(apply_translation, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deep_translator import GoogleTranslator\n",
    "# import pandas as pd\n",
    "# import ast  # To safely convert string representation of lists\n",
    "\n",
    "\n",
    "# # Function to split long texts into chunks\n",
    "# def chunk_text(text, chunk_size=4000):\n",
    "#     # Split the text into smaller chunks\n",
    "#     return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# # Function to translate tokenized sentences\n",
    "# def translate_sentences(tokenized_list, src_lang=\"auto\", target_lang=\"en\"):\n",
    "   \n",
    "        \n",
    "#         # Split text into smaller chunks\n",
    "#         chunks = chunk_text(tokenized_list)\n",
    "        \n",
    "#         # Translate each chunk separately\n",
    "#         translated_chunks = [\n",
    "#             GoogleTranslator(source=src_lang, target=target_lang).translate(chunk) for chunk in chunks\n",
    "#         ]\n",
    "        \n",
    "#         # Recombine the translated chunks into one string\n",
    "#         return \" \".join(translated_chunks)\n",
    "    \n",
    "\n",
    "\n",
    "# # Apply translation to tokenized sentences\n",
    "# snippet[\"translated_text\"] = snippet[\"normalized_text\"].apply(translate_sentences)\n",
    "\n",
    "# snippet.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deep_translator import GoogleTranslator\n",
    "# import pandas as pd\n",
    "# import ast  # To safely convert string representation of lists\n",
    "\n",
    "\n",
    "# # Function to split long texts into chunks\n",
    "# def chunk_text(text, chunk_size=2000):\n",
    "#     # Split the text into smaller chunks\n",
    "#     return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# # Function to translate tokenized sentences\n",
    "# def translate_sentences(tokenized_list, src_lang=\"auto\", target_lang=\"en\"):\n",
    "#     # try:\n",
    "#     #     # Convert string to list if needed\n",
    "#     #     if isinstance(tokenized_list, str):\n",
    "#     #         tokenized_list = ast.literal_eval(tokenized_list)\n",
    "            \n",
    "#     #     # Join tokenized sentences into a single string\n",
    "#     #     text_to_translate = \" \".join(tokenized_list)\n",
    "        \n",
    "#         # Split text into smaller chunks\n",
    "#         chunks = chunk_text(tokenized_list)\n",
    "        \n",
    "#         # Translate each chunk separately\n",
    "#         translated_chunks = [\n",
    "#             GoogleTranslator(source=src_lang, target=target_lang).translate(chunk) for chunk in chunks\n",
    "#         ]\n",
    "        \n",
    "#         # Recombine the translated chunks into one string\n",
    "#         try:\n",
    "#             # Your translation logic\n",
    "#             return \" \".join(translated_chunks)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error translating: {e}\")  # Debugging\n",
    "#             return \"Translation Failed\"\n",
    "\n",
    "    \n",
    "#     # except Exception as e:\n",
    "#     #     return f\"Error: {e}\"\n",
    "\n",
    "# # Apply translation to tokenized sentences\n",
    "# data_1[\"translated_text\"] = data_1[\"normalized_text\"].apply(translate_sentences)\n",
    "\n",
    "# data_1.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation attemt vol 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The name Phone Send 0 Add Goods to Wishes 0 Add Goods to Compare Working Time: 12:00 - 19:00 0 My Order PALTY All Coats De-season Coat Winter Women's Coat Winter Coat Coat Casual Coat Casual Coat Plate Pallet with Capuchon PAllet with Capuchon NATURAL FISHERIES All Shoes All Shoes All Shoes of the Horses All Shoes of the Horses All Shoes of the Northern Territory All Shoes of the Northern Territory The Shoes of the Northern Territory The Shoes of the Northern Territory The Shoes of the Capuchon PAllet with Capuchon Transformers of the Northern Territory The Highest Prices in Kyiv and Ukraine The Shoes of the Blue-nose Shoe Shoe-drivers of the Northern Territory The Shoes of the Muton The Shoes of the\"]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "article_fr = \"\"\"Купить Шубуиз Натурального Меха: Лучшие Цены в Киеве и Украине | Chicly-Furs Рус Укр МАГАЗИН В КИЕВЕ Контакты О нас Доставка и оплата Обмен и возврат Советы Отзывы Вход +38 (067) 440 47 00 Перезвонить вам? Перезвонить вам? Укажите ваш номер телефона и имя. Мы свяжемся с вами в ближайшее время. Имя Телефон Отправить 0 Добавьте товары в желания 0 Добавьте товары для сравнения График работы: 12:00 - 19:00 0 Мой заказ ПАЛЬТО Все пальто Пальто демисезонные Пальто зимние женские Все зимние пальто Зимние пальто с мехом Кашемировые пальто Пальто с мехом Плащи Пальто с капюшоном НАТУРАЛЬНЫЕ ШУБЫ Все шубы Шубы норковые Все норковые шубы Полушубки норковые Норковые шубы с капюшоном Трансформеры из норки Элитная норка Норковые шубы больших размеров Шубы из голубой норки Шубы-автоледи из норки Шубы из мутона Все шубы из мутона Полушубки из мутона Полушубки Шубы из нутрии Все шубы из нутрии Трансформеры из нутрии Полушубки из нутрии Шубы из песца Все шубы из песца Трансформеры из песца Полушубок из песца Меховые кардиганы Шубы из бобрика (кролика рэкс) Все шубы из кролика рэкса Трансформеры из кролика Полушубки из бобрика (кролика рэкс) Трансформеры Шубы из кролика Все шубы из кролика Полушубки из кролика Шубы из куницы Все шубы из куницы Полушубки из куницы Шубы из каракуля Шубы из чернобурки Все шубы из чернобурки Полушубки из чернобурки Трансформеры из чернобурки Шубы из бобра Шубы из редких мехов Все шубы с эксклюзивного меха Трансформеры из редких мехов Полушубки из эксклюзивных мехов Шубы из лисы Все шубы из лисы Трансформеры из лисы Полушубки из лисы КУРТКИ Все куртки Дубленки натуральные Эко дубленки Зимние куртки Меховые куртки Куртки-дутики Куртки из экокожи ШУБЫ ИЗ ЭКО-МЕХА Шубы из эко-меха зимние Демисезонные искусственные шубы Куртки из эко-меха ЖИЛЕТКИ Все жилетки Жилетки из песца Жилетки из чернобурки Жилетки из норки Жилетки из кролика Жилетки из лисы Кашемировые жилеты с мехом Жилетки из кашемира и дутики Жилетки из редких мехов Жилетки из ламы Жилетки из шиншиллового кролика ПУХОВИКИ Пуховики зимние Пуховики осень-весна ПАРКА Парки женские Все женские парки Парки зимние АКСЕССУАРЫ Перчатки женские Головные уборы Шапки меховые женские Платки меховые Сумки Меховые накидки Шарфы меховые женские Пояса Чехлы для верхней одежды ОДЕЖДА Вся одежда Кардиганы и кофты Платья Спортивные костюмы Костюмы Юбки Гольфы и свитера Джинсы Пиджаки и рубашки Брюки и леггинсы Сарафаны и топы   2012—2025 \"ШИКАРНЫЕ МЕХА\" Все тексты и графические материалы на сайте являются собственностью компании, копирование без уведомления и любое их использование преследуется по Закону Украины. Мобильная версия Каталог ПАЛЬТО НАТУРАЛЬНЫЕ ШУБЫ КУРТКИ ШУБЫ ИЗ ЭКО-МЕХА ЖИЛЕТКИ ПУХОВИКИ ПАРКА АКСЕССУАРЫ ОДЕЖДА \"\"\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# translate French to English\n",
    "tokenizer.src_lang = \"ru_XX\"\n",
    "encoded_fr = tokenizer(article_fr, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_fr, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "translation =tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "print(translation)\n",
    "# => \"Hello, how are you?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Buy Natural Wood Shoes: Best Prices in Kiev and Ukraine | Chicly-Furs Рус Укр МАГАЗИН В К Киев Contacts About us Shipping and Payment Change and Return Tips Reviews Input +38 (067) 440 47 00 Call you back? Call you back? Enter your phone number and name. We will contact you in the near future. Name Phone Send 0 Add products to wishes 0 Add products for comparison Working time: 12:00 - 19:00 0 My order PALTO All collars De-season collars Winter collars Winter collars Winter collars Kashmir collars Leather collars Leather collars Natural Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes All Wood Shoes']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "\n",
    "article_ar = \"\"\"Купить Шубуиз Натурального Меха: Лучшие Цены в Киеве и Украине | Chicly-Furs Рус Укр МАГАЗИН В КИЕВЕ Контакты О нас Доставка и оплата Обмен и возврат Советы Отзывы Вход +38 (067) 440 47 00 Перезвонить вам? Перезвонить вам? Укажите ваш номер телефона и имя. Мы свяжемся с вами в ближайшее время. Имя Телефон Отправить 0 Добавьте товары в желания 0 Добавьте товары для сравнения График работы: 12:00 - 19:00 0 Мой заказ ПАЛЬТО Все пальто Пальто демисезонные Пальто зимние женские Все зимние пальто Зимние пальто с мехом Кашемировые пальто Пальто с мехом Плащи Пальто с капюшоном НАТУРАЛЬНЫЕ ШУБЫ Все шубы Шубы норковые Все норковые шубы Полушубки норковые Норковые шубы с капюшоном Трансформеры из норки Элитная норка Норковые шубы больших размеров Шубы из голубой норки Шубы-автоледи из норки Шубы из мутона Все шубы из мутона Полушубки из мутона Полушубки Шубы из нутрии Все шубы из нутрии Трансформеры из нутрии Полушубки из нутрии Шубы из песца Все шубы из песца Трансформеры из песца Полушубок из песца Меховые кардиганы Шубы из бобрика (кролика рэкс) Все шубы из кролика рэкса Трансформеры из кролика Полушубки из бобрика (кролика рэкс) Трансформеры Шубы из кролика Все шубы из кролика Полушубки из кролика Шубы из куницы Все шубы из куницы Полушубки из куницы Шубы из каракуля Шубы из чернобурки Все шубы из чернобурки Полушубки из чернобурки Трансформеры из чернобурки Шубы из бобра Шубы из редких мехов Все шубы с эксклюзивного меха Трансформеры из редких мехов Полушубки из эксклюзивных мехов Шубы из лисы Все шубы из лисы Трансформеры из лисы Полушубки из лисы КУРТКИ Все куртки Дубленки натуральные Эко дубленки Зимние куртки Меховые куртки Куртки-дутики Куртки из экокожи ШУБЫ ИЗ ЭКО-МЕХА Шубы из эко-меха зимние Демисезонные искусственные шубы \"\"\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# translate Arabic to English\n",
    "tokenizer.src_lang = \"ru_RU\"\n",
    "encoded_ar = tokenizer(article_ar, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(**encoded_ar, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "# => \"The Secretary-General of the United Nations says there is no military solution in Syria.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Afrikaans': 'af', 'Amharic': 'am', 'Arabic': 'ar', 'Asturian': 'ast', 'Azerbaijani': 'az', 'Bashkir': 'ba', 'Belarusian': 'be', 'Bulgarian': 'bg', 'Bengali': 'bn', 'Breton': 'br', 'Bosnian': 'bs', 'Catalan': 'ca', 'Valencian': 'ca', 'Cebuano': 'ceb', 'Czech': 'cs', 'Welsh': 'cy', 'Danish': 'da', 'German': 'de', 'Greek': 'el', 'English': 'en', 'Spanish': 'es', 'Estonian': 'et', 'Persian': 'fa', 'Fulah': 'ff', 'Finnish': 'fi', 'French': 'fr', 'Western Frisian': 'fy', 'Irish': 'ga', 'Gaelic': 'gd', 'Scottish Gaelic': 'gd', 'Galician': 'gl', 'Gujarati': 'gu', 'Hausa': 'ha', 'Hebrew': 'he', 'Hindi': 'hi', 'Croatian': 'hr', 'Haitian': 'ht', 'Haitian Creole': 'ht', 'Hungarian': 'hu', 'Armenian': 'hy', 'Indonesian': 'id', 'Igbo': 'ig', 'Iloko': 'ilo', 'Icelandic': 'is', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jv', 'Georgian': 'ka', 'Kazakh': 'kk', 'Khmer': 'km', 'Central Khmer': 'km', 'Kannada': 'kn', 'Korean': 'ko', 'Luxembourgish': 'lb', 'Letzeburgesch': 'lb', 'Ganda': 'lg', 'Lingala': 'ln', 'Lao': 'lo', 'Lithuanian': 'lt', 'Latvian': 'lv', 'Malagasy': 'mg', 'Macedonian': 'mk', 'Malayalam': 'ml', 'Mongolian': 'mn', 'Marathi': 'mr', 'Malay': 'ms', 'Burmese': 'my', 'Nepali': 'ne', 'Dutch': 'nl', 'Flemish': 'nl', 'Norwegian': 'no', 'Northern Sotho': 'ns', 'Occitan': 'oc', 'Oriya': 'or', 'Panjabi': 'pa', 'Punjabi': 'pa', 'Polish': 'pl', 'Pushto': 'ps', 'Pashto': 'ps', 'Portuguese': 'pt', 'Romanian': 'ro', 'Moldavian': 'ro', 'Moldovan': 'ro', 'Russian': 'ru', 'Sindhi': 'sd', 'Sinhala': 'si', 'Sinhalese': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Albanian': 'sq', 'Serbian': 'sr', 'Swati': 'ss', 'Sundanese': 'su', 'Swedish': 'sv', 'Swahili': 'sw', 'Tamil': 'ta', 'Thai': 'th', 'Tagalog': 'tl', 'Tswana': 'tn', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Wolof': 'wo', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Chinese': 'zh', 'Zulu': 'zu'}\n"
     ]
    }
   ],
   "source": [
    "import dl_translate as dlt\n",
    "\n",
    "mt = dlt.TranslationModel()  # Slow when you load it for the first time\n",
    "#print(mt.available_languages())  # All languages that you can use\n",
    "#print(mt.available_codes())  # Code corresponding to each language accepted\n",
    "print(mt.get_lang_code_map())  # Dictionary of lang -> code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Shubuiz Natural Mecha: Best Prices in Kiev and Ukraine | Chicly-Furs Рус Укр МАГАЗИН В КЕЙВЕ Contacts About us Shipping and Payment Exchange and Return Tips Reviews Input +38 (067) 440 47 00 Call you? Call you? Enter your phone number and name. We will contact you soon. Name Phone Send 0 Add products to wishes 0 Add products for comparison Working time: 12:00 - 19:00 0 My order PALTO All trousers Demise trousers Winter trousers Women's winter trousers All winter trousers Winter Leather Pants Kashmiri Pants Leather Pants Leather Pants Capuchon Pants NATURAL SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH SOUTH from sand Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals Wooden carnivals leather Shoes of linen All shoes of linen Transformers of linen Half-sleeves of linen T-shirts All jackets Natural Duplicates Eco Duplicates Winter jackets Leather jackets Leather jackets Leather jackets Leather jackets Leather jackets Winter jackets Seasonal Artificial Shoes\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import textwrap\n",
    "\n",
    "def translate(text, src_lang=\"ru_RU\", tgt_lang=\"en_XX\", max_chunk_size=500):\n",
    "    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "    tokenizer.src_lang = src_lang\n",
    "    translated_text = []\n",
    "\n",
    "    # Split text into manageable chunks\n",
    "    for chunk in textwrap.wrap(text, max_chunk_size):\n",
    "        encoded = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang], max_length=1024)\n",
    "        translated_text.append(tokenizer.decode(generated_tokens[0], skip_special_tokens=True))\n",
    "\n",
    "    return \" \".join(translated_text)\n",
    "\n",
    "article_ru = \"\"\"Купить Шубуиз Натурального Меха: Лучшие Цены в Киеве и Украине | Chicly-Furs Рус Укр МАГАЗИН В КИЕВЕ Контакты О нас Доставка и оплата Обмен и возврат Советы Отзывы Вход +38 (067) 440 47 00 Перезвонить вам? Перезвонить вам? Укажите ваш номер телефона и имя. Мы свяжемся с вами в ближайшее время. Имя Телефон Отправить 0 Добавьте товары в желания 0 Добавьте товары для сравнения График работы: 12:00 - 19:00 0 Мой заказ ПАЛЬТО Все пальто Пальто демисезонные Пальто зимние женские Все зимние пальто Зимние пальто с мехом Кашемировые пальто Пальто с мехом Плащи Пальто с капюшоном НАТУРАЛЬНЫЕ ШУБЫ Все шубы Шубы норковые Все норковые шубы Полушубки норковые Норковые шубы с капюшоном Трансформеры из норки Элитная норка Норковые шубы больших размеров Шубы из голубой норки Шубы-автоледи из норки Шубы из мутона Все шубы из мутона Полушубки из мутона Полушубки Шубы из нутрии Все шубы из нутрии Трансформеры из нутрии Полушубки из нутрии Шубы из песца Все шубы из песца Трансформеры из песца Полушубок из песца Меховые кардиганы Шубы из бобрика (кролика рэкс) Все шубы из кролика рэкса Трансформеры из кролика Полушубки из бобрика (кролика рэкс) Трансформеры Шубы из кролика Все шубы из кролика Полушубки из кролика Шубы из куницы Все шубы из куницы Полушубки из куницы Шубы из каракуля Шубы из чернобурки Все шубы из чернобурки Полушубки из чернобурки Трансформеры из чернобурки Шубы из бобра Шубы из редких мехов Все шубы с эксклюзивного меха Трансформеры из редких мехов Полушубки из эксклюзивных мехов Шубы из лисы Все шубы из лисы Трансформеры из лисы Полушубки из лисы КУРТКИ Все куртки Дубленки натуральные Эко дубленки Зимние куртки Меховые куртки Куртки-дутики Куртки из экокожи ШУБЫ ИЗ ЭКО-МЕХА Шубы из эко-меха зимние Демисезонные искусственные шубы \"\"\"  # Full text here\n",
    "translated_text = translate(article_ru)\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_map = {\n",
    "    \"da\": \"da_DK\", \"fr\": \"fr_XX\", \"es\": \"es_XX\", \"en\": \"en_XX\", \"ru\": \"ru_RU\",\n",
    "    \"ja\": \"ja_XX\", \"ko\": \"ko_KR\", \"it\": \"it_IT\", \"zh-cn\": \"zh_CN\", \"lt\": \"lt_LT\",\n",
    "    \"no\": \"no_XX\", \"de\": \"de_DE\", \"sl\": \"sl_SI\", \"nl\": \"nl_XX\", \"vi\": \"vi_VN\",\n",
    "    \"th\": \"th_TH\", \"sv\": \"sv_SE\", \"ar\": \"ar_AR\", \"hr\": \"hr_HR\", \"el\": \"el_GR\",\n",
    "    \"pt\": \"pt_XX\", \"id\": \"id_ID\", \"tr\": \"tr_TR\", \"he\": \"he_IL\", \"sk\": \"sk_SK\",\n",
    "    \"ro\": \"ro_RO\", \"cs\": \"cs_CZ\", \"pl\": \"pl_PL\", \"hu\": \"hu_HU\", \"lv\": \"lv_LV\",\n",
    "    \"et\": \"et_EE\", \"ca\": \"ca_XX\", \"fi\": \"fi_FI\", \"bg\": \"bg_BG\", \"uk\": \"uk_UA\",\n",
    "    \"sq\": \"sq_AL\", \"mk\": \"mk_MK\", \"bn\": \"bn_IN\"  # Bengali\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1[\"mbart_lang_code\"] = data_1[\"detected_language\"].map(lang_map).fillna(\"en_XX\")  # Default to English if unknown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Snipppet_3000_1=data_1.iloc[:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import textwrap\n",
    "\n",
    "def translate(text, src_lang, tgt_lang=\"en_XX\", max_chunk_size=500):\n",
    "    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "    tokenizer.src_lang = src_lang\n",
    "    translated_text = []\n",
    "\n",
    "    # Split text into manageable chunks\n",
    "    for chunk in textwrap.wrap(text, max_chunk_size):\n",
    "        encoded = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang], max_length=1024)\n",
    "        translated_text.append(tokenizer.decode(generated_tokens[0], skip_special_tokens=True))\n",
    "\n",
    "    return \" \".join(translated_text)\n",
    "\n",
    "\n",
    "Snipppet_3000_1[\"translated_text\"] = Snipppet_3000_1.apply(\n",
    "    lambda row: row[\"normalized_text\"] if row[\"mbart_lang_code\"] == \"en_XX\" \n",
    "    else translate(row[\"normalized_text\"], row[\"mbart_lang_code\"]), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Snipppet_3000_1.to_csv(\"Translated_3000_non.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/jfilter/clean-text/blob/main/README.md\n",
    "\n",
    "https://stackoverflow.com/questions/68587883/python-translate-large-texts-to-english\n",
    "\n",
    "https://github.com/xhluca/dl-translate/blob/main/README.md\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
